{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Task the MNIST Sequence Dataset is used(see https://github.com/edwin-de-jong/mnist-digits-stroke-sequence-data/wiki/MNIST-digits-stroke-sequence-data) to train a sequence prediction model. The dataset consists of sequences generated from the famous MNIST dataset. Based on an input sequences our Model has to predict the remaining sequence. To process the input sequence an encoder model is used. To predict the future sequence a decoder model is used. Additionally a AttentionDecoder is implemented however the code has to be changed to use this Decoder \n",
    "\n",
    "![Bild1.png](attachment:Bild1.png)\n",
    "\n",
    "This Tutorial is based on the PyTorch introduction Tutorials (https://pytorch.org/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from download import download_file_from_google_drive\n",
    "from common import load_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Set parameters\n",
    "#####################\n",
    "\n",
    "# Data params\n",
    "noise_var = 0\n",
    "num_datapoints = 100\n",
    "test_size = 0.2\n",
    "num_train = int((1 - test_size) * num_datapoints)\n",
    "\n",
    "# Network params\n",
    "input_size = 2\n",
    "hidden_layer = 128\n",
    "output_dim = input_size\n",
    "num_layers = 2\n",
    "num_epochs = 500\n",
    "dtype = torch.float\n",
    "input_seq = 60\n",
    "pred_length = 20\n",
    "batch_size = 32\n",
    "train_samples = 10\n",
    "test_samples = 100\n",
    "\n",
    "device = \"cpu\"  # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The loading and preprocessing is based on the implementation of https://github.com/edwin-de-jong/incremental-sequence-learning.\n",
    "\n",
    "The Data is Downlaoded as numpy files from my personal Google Drive. \n",
    "Numpy Data available at https://drive.google.com/file/d/1uaVImXWqdbEhj9euCw8EMKJKsJ7uS7I2/view?usp=sharing\n",
    "\n",
    "If not possible the Dataset can also be downloaded from https://github.com/edwin-de-jong/mnist-digits-stroke-sequence-data/raw/master/sequences.tar.gz, extracted and processed by load_data()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 60, 2)\n",
      "(60000, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Load data\n",
    "#####################\n",
    "\n",
    "file_id = '1XHWS4PqmnMaR2pID0bPsVtVeohZpKgTF'\n",
    "destination = './extracted_data_label.npz'\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "def prepare_data(data, train=True):\n",
    "    if train:\n",
    "        x = data[0:60000, 0:input_seq, :]\n",
    "        y = data[0:60000, input_seq:input_seq+pred_length, :]\n",
    "        x = x[0:int(x.shape[0] / batch_size) * batch_size, :]\n",
    "        y = y[0:int(x.shape[0] / batch_size) * batch_size, :]\n",
    "        return (x, y)\n",
    "    else:\n",
    "        x = data[60000:, 0:input_seq, :]\n",
    "        y = data[60000:, input_seq:input_seq+pred_length, :]\n",
    "        x = x[0:int(x.shape[0] / batch_size) * batch_size, :]\n",
    "        y = y[0:int(x.shape[0] / batch_size) * batch_size, :]\n",
    "        return (x, y)\n",
    "\n",
    "data, _ = load_data()\n",
    "(x_data, y_data) = prepare_data(data, train=True)\n",
    "(x_data_test, y_data_test) = prepare_data(data, train=False)\n",
    "\n",
    "output_seq = y_data.shape[1]\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 60, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bdb9fe\\appdata\\local\\continuum\\anaconda3\\envs\\pt36\\lib\\site-packages\\matplotlib\\pyplot.py:3358: RuntimeWarning: Second argument 'y' is ambiguous: could be a color spec but is in data; using as data.  Either rename the entry in data or use three arguments to plot.\n",
      "  ret = ax.plot(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, data_x, data_y, batch_size=batch_size, output_seq=output_seq, n_action=2):\n",
    "        self.data_x = data_x  # np.reshape(data_x, (data_x.shape[0], -1))\n",
    "        self.data_y = data_y  # np.reshape(data_y, (data_y.shape[0], -1))\n",
    "        self.batch_size = batch_size\n",
    "        self.output_seq = output_seq\n",
    "        self.n_action = n_action\n",
    "\n",
    "    def sample(self, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        indices = np.random.randint(0, len(self.data_x), batch_size)\n",
    "        x_batch = torch.tensor(self.data_x[indices, :, :]).to(torch.float)\n",
    "        y_batch = torch.tensor(self.data_y[indices, :, :]).to(torch.float)\n",
    "        return x_batch, y_batch\n",
    "\n",
    "\n",
    "def draw(sequence):\n",
    "    to_plot = np.array(sequence).squeeze(1)\n",
    "    df = pd.DataFrame({'x': to_plot[:, 0], 'y': to_plot[:, 1]})\n",
    "    plt.plot('x', 'y', data=df, linestyle='-', marker='o')\n",
    "\n",
    "train_data_generator = BatchGenerator(x_data, y_data, batch_size=batch_size)\n",
    "test_data_generator = BatchGenerator(x_data_test, y_data_test, batch_size=batch_size)\n",
    "\n",
    "x_batch, y_batch = train_data_generator.sample()\n",
    "print(x_batch.shape)\n",
    "draw(torch.cat((x_batch[0, :, :], y_batch[0, :, :]), 0).cpu().unsqueeze(1).numpy().astype(np.float))"
   ]
  },
  {
   "attachments": {
    "grafik.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "\n",
    "### Encoder\n",
    "\n",
    "An encoder RNN using a GRU layer is used to encode the input sequence. \n",
    "![grafik.png](attachment:grafik.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size=32):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.linear = nn.Linear(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        output = self.linear(input).view(1, batch_size, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "The output sequence is predicted using the DecoderRNN which also uses a GRU layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, batch_size=32):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.linear = nn.Linear(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        output = self.linear(input).view(1, batch_size, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder\n",
    "The AttnDecoderRNN uses a Attention layer which enables the Decoder to process all hidden states from the decoder and only paying attention to the neccessary ones. To use this RNN you have to change the training routine (you have to save all hidden states of the decoder and pass it to the attention decoder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=output_seq):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.linear = nn.Linear(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.linear(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_size, hidden_layer, batch_size=batch_size).to(device)\n",
    "decoder = DecoderRNN(hidden_layer, output_dim, batch_size=batch_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function\n",
    "The training function is similar to the first tutorial. This time we first encode the input sequence and than predict the output sequence using the decoder. \n",
    "\n",
    "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster but when the trained network is exploited, it may exhibit instability. To avoid the instability it is randomly selected which approach is used to estimate the next input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Train Function\n",
    "#####################\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 5e-4\n",
    "# optimiser = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(x_tensor, y_tensor):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for e_i in range(x_tensor.size()[1]):\n",
    "        input_tensor = x_tensor[:, e_i, :]\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = input_tensor\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for d_i in range(y_tensor.size()[1]):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            l = loss_fn(decoder_output, y_tensor[:, d_i, :])\n",
    "            loss += l\n",
    "            decoder_input = y_tensor[:, d_i, :]\n",
    "    else:\n",
    "        for d_i in range(y_tensor.size()[1]):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            l = loss_fn(decoder_output, y_tensor[:, d_i, :])\n",
    "            loss += l\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def predict(x_tensor, y_tensor, batch_size):\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = torch.zeros(1, batch_size, encoder.hidden_size, device=device)  #  encoder.initHidden()\n",
    "        loss = 0\n",
    "        sequence = []\n",
    "        for e_i in range(x_tensor.size()[1]):\n",
    "            input_tensor = x_tensor[:, e_i, :]\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "            sequence.append(input_tensor.cpu().numpy().astype(np.float))\n",
    "\n",
    "        decoder_input = input_tensor\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for d_i in range(y_tensor.size()[1]):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            l = loss_fn(decoder_output, y_tensor[:, d_i, :])\n",
    "            loss += l\n",
    "            decoder_input = decoder_output\n",
    "            sequence.append(decoder_output.cpu().numpy().astype(np.float))\n",
    "\n",
    "    return loss.item(), sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Since we have a bigger model and more data to process now the training may take a while to converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss:  1384.8288513183593\n",
      "current_test_loss:  883.3004150390625\n",
      "current_loss:  743.1156066894531\n",
      "current_test_loss:  619.4346313476562\n",
      "current_loss:  531.9915893554687\n",
      "current_test_loss:  337.6059265136719\n",
      "current_loss:  517.8850067138671\n",
      "current_test_loss:  502.6859436035156\n",
      "current_loss:  409.39453125\n",
      "current_test_loss:  390.7309875488281\n",
      "current_loss:  403.6657440185547\n",
      "current_test_loss:  1051.936279296875\n",
      "current_loss:  445.6460296630859\n",
      "current_test_loss:  404.45233154296875\n",
      "current_loss:  394.38495178222655\n",
      "current_test_loss:  489.63543701171875\n",
      "current_loss:  341.2698440551758\n",
      "current_test_loss:  750.2383422851562\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-21f93de5744e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# category, line, category_tensor, line_tensor = randomTrainingExample()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-59599ec0117c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(x_tensor, y_tensor)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bdb9fe\\appdata\\local\\continuum\\anaconda3\\envs\\pt36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bdb9fe\\appdata\\local\\continuum\\anaconda3\\envs\\pt36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 200000\n",
    "plot_every = 1000\n",
    "test_size = batch_size\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "all_test_losses = []\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    x_batch, y_batch = train_data_generator.sample()\n",
    "    # category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    loss = train(x_batch, y_batch)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        print(\"current_loss: \", current_loss/plot_every)\n",
    "        all_losses.append(current_loss/plot_every)\n",
    "        current_loss = 0\n",
    "        # test_loss\n",
    "        x_test_batch, y_test_batch = test_data_generator.sample(batch_size=test_size)\n",
    "        test_loss, _ = predict(x_test_batch, y_test_batch, batch_size=test_size)\n",
    "        print(\"current_test_loss: \", test_loss)\n",
    "        all_test_losses.append(test_loss)\n",
    "\n",
    "x_test_batch, y_test_batch = test_data_generator.sample(batch_size=5)\n",
    "for i in range(y_test_batch.size()[0]):\n",
    "    test_loss, sequence = predict(x_test_batch[i, :, :].unsqueeze(0), y_test_batch[i, :, :].unsqueeze(0), batch_size=1)\n",
    "    draw(sequence)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(all_test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
